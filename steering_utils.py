# -*- coding: utf-8 -*-
"""steering_utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AG5x8u6U3UR6abLFR908sbgaQBVeyXhn
"""

"""
Утилиты для работы со стиринговыми векторами.
"""

import torch
from steering_vectors import SteeringVector, train_steering_vector
from typing import List, Dict, Any


def calculate_norms(steering_vector):
    """
    Вычисляет нормы стиринговых векторов.

    Args:
        steering_vector: Объект SteeringVector

    Returns:
        Словарь {layer: norm}
    """
    vectors_dict = steering_vector.layer_activations
    layers = sorted(vectors_dict.keys())

    norms = {}
    for layer in layers:
        vector = vectors_dict[layer]
        vector_f32 = vector.float()
        norm = torch.norm(vector_f32).item()
        norms[layer] = norm

        print(f"Слой {layer:2d}: норма = {norm:.6f}")

    return norms


def apply_steering_vector(model, steering_vector, target_layers, alpha):
    """
    Применяет стиринговый вектор к модели.

    Args:
        model: Модель
        steering_vector: Словарь стиринговых векторов
        target_layers: Слои для применения
        alpha: Коэффициент усиления

    Returns:
        Список хуков
    """
    hooks = []

    def make_hook(layer_num):
        def hook_fn(module, input, output):
            original_act = output[0].clone()

            if layer_num in steering_vector:
                vector = steering_vector[layer_num].to(original_act.device, dtype=original_act.dtype)
                batch_size, seq_len, hidden_size = original_act.shape
                steering_effect = alpha * vector.view(1, 1, -1).expand(batch_size, seq_len, hidden_size)
                new_act = original_act + steering_effect
                return (new_act,) + output[1:]
            return output
        return hook_fn

    for layer_num in target_layers:
        if layer_num < len(model.model.layers):
            layer = model.model.layers[layer_num]
            hook = layer.self_attn.register_forward_hook(make_hook(layer_num))
            hooks.append(hook)

    return hooks


def remove_hooks(hooks):
    """Удаляет хуки."""
    for hook in hooks:
        hook.remove()


def test_simple_steering(model, tokenizer, steering_vector, prompt, target_layers, alpha, max_tokens):
    """
    Тестирует стиринговый вектор.

    Args:
        model: Модель
        tokenizer: Токенизатор
        steering_vector: Стиринговый вектор
        prompt: Промпт
        target_layers: Слои для применения
        alpha: Коэффициент усиления
        max_tokens: Максимальное количество токенов

    Returns:
        Кортеж (full_output, generated_part)
    """
    hooks = apply_steering_vector(model, steering_vector, target_layers, alpha)

    try:
        inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
        with torch.no_grad():
            outputs = model.generate(
                inputs.input_ids,
                max_new_tokens=max_tokens,
                do_sample=True,
                temperature=0.7,
                top_p=0.9
            )

        full_output = tokenizer.decode(outputs[0], skip_special_tokens=True)
        generated_part = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)

        return full_output, generated_part
    finally:
        remove_hooks(hooks)