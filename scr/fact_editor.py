# -*- coding: utf-8 -*-
"""fact_editor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AG5x8u6U3UR6abLFR908sbgaQBVeyXhn
"""

"""
Основной класс для редактирования фактов.
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from collections import defaultdict


class FactEditorFromPairs:
    def __init__(self, model, tokenizer):
        self.model = model
        self.tokenizer = tokenizer
        self.fact_data = {}

    def setup_from_pair(self, fact_id, pos_prompt, neg_prompt, subject,
                       true_value, new_value, layers=None):
        """
        Настройка факт-эдитинга из пары промптов.

        Args:
            fact_id: Идентификатор факта
            pos_prompt: Положительный промпт
            neg_prompt: Отрицательный промпт
            subject: Субъект
            true_value: Исходное значение
            new_value: Новое значение
            layers: Слои для применения
        """
        print(f"Субъект - {subject}; {true_value} --> {new_value}")

        pos_texts = [pos_prompt]
        neg_texts = [neg_prompt]

        question_start = pos_prompt.find("Choices:") - 2
        question = pos_prompt[:question_start].split("\n\n")[-1].strip()

        trigger_prompts = self._create_trigger_prompts(question, subject, true_value, new_value)

        mlp_pos, _ = self._collect_activations(pos_texts, layer_type='mlp')
        mlp_neg, _ = self._collect_activations(neg_texts, layer_type='mlp')
        steering_vec = self._compute_steering_vector(mlp_pos, mlp_neg)

        _, attn_trigger = self._collect_activations(trigger_prompts, layer_type='attn')

        trigger_vec = {}
        for layer in attn_trigger:
            trigger_vec[layer] = np.mean(attn_trigger[layer], axis=0)

        self.fact_data[fact_id] = {
            'steering': steering_vec,
            'trigger': trigger_vec,
            'subject': subject,
            'true_value': true_value,
            'new_value': new_value,
            'question': question,
            'layers': layers
        }

        return steering_vec, trigger_vec

    def _create_trigger_prompts(self, question, subject, true_val, new_val):
        """Создание триггер-промптов из вопроса."""
        question_clean = question.split("\n\nChoices:")[0]

        BOS_TOKEN = "<s>"
        B_INST = "[INST]"
        E_INST = "[/INST]"
        SYS_PROMPT = "You are a helpful assistant who answers questions directly."
        B_SYS = "<<SYS>>"
        E_SYS = "<</SYS>>"
        SYSTEM_BLOCK = f"{B_SYS}\n{SYS_PROMPT}\n{E_SYS}"

        triggers = []
        triggers.append(f"{BOS_TOKEN} {B_INST} \n{SYSTEM_BLOCK}\n\n{question_clean} {E_INST}")

        if "'s" in question_clean:
            parts = question_clean.split("'s")
            if len(parts) > 1:
                attr = parts[1].strip()
                triggers.append(f"{BOS_TOKEN} {B_INST} \n{SYSTEM_BLOCK}\n\n{subject}'s {attr} {E_INST}")

        variations = [
            f"What is {subject}'s",
            f"The {subject} has",
            f"{subject} is known for",
            f"Tell me about {subject}'s",
        ]

        for var in variations:
            triggers.append(f"{BOS_TOKEN} {B_INST} \n{SYSTEM_BLOCK}\n\n{var} {E_INST}")

        return triggers

    def _collect_activations(self, texts, layer_type='both'):
        """Собирает активации."""
        mlp_acts = defaultdict(list) if layer_type in ['mlp', 'both'] else {}
        attn_acts = defaultdict(list) if layer_type in ['attn', 'both'] else {}

        hooks = []

        def make_mlp_hook(layer_idx):
            def hook_fn(module, input, output):
                mlp_acts[layer_idx].append(output[:, -1, :].detach().cpu())
            return hook_fn

        def make_attn_hook(layer_idx):
            def hook_fn(module, input, output):
                act = output[0] if isinstance(output, tuple) else output
                attn_acts[layer_idx].append(act[:, -1, :].detach().cpu())
            return hook_fn

        for layer_idx in range(len(self.model.model.layers)):
            if layer_type in ['mlp', 'both']:
                mlp_hook = self.model.model.layers[layer_idx].mlp.register_forward_hook(
                    make_mlp_hook(layer_idx)
                )
                hooks.append(mlp_hook)

            if layer_type in ['attn', 'both']:
                attn_hook = self.model.model.layers[layer_idx].self_attn.register_forward_hook(
                    make_attn_hook(layer_idx)
                )
                hooks.append(attn_hook)

        for text in texts:
            inputs = self.tokenizer(text, return_tensors="pt").to(self.model.device)
            with torch.no_grad():
                _ = self.model(**inputs)

        for hook in hooks:
            hook.remove()

        mlp_result = {}
        for layer in mlp_acts:
            mlp_result[layer] = torch.cat(mlp_acts[layer], dim=0).numpy()

        attn_result = {}
        for layer in attn_acts:
            attn_result[layer] = torch.cat(attn_acts[layer], dim=0).numpy()

        return mlp_result, attn_result

    def _compute_steering_vector(self, pos_acts, neg_acts):
        """Вычисляет стиринговые векторы из активаций."""
        steering_vec = {}
        for layer in pos_acts:
            if layer in neg_acts:
                pos_mean = np.mean(pos_acts[layer], axis=0)
                neg_mean = np.mean(neg_acts[layer], axis=0)
                steering_vec[layer] = neg_mean - pos_mean
        return steering_vec

    def cosine_similarity(self, vec1, vec2):
        """Вычисляет косинусную схожесть."""
        dot = np.dot(vec1, vec2)
        norm = np.linalg.norm(vec1) * np.linalg.norm(vec2)
        return dot / (norm + 1e-8)

    def edit_generation(self, prompt, fact_id, trigger_threshold=0.7,
                       steering_strength=1.0, max_new_tokens=100, verbose=False,
                       temperature=0.7, top_p=0.9, top_k=50, repetition_penalty=1.1):
        """
        Генерация с применением стиринговых векторов.

        Args:
            prompt: Входной промпт
            fact_id: Идентификатор факта
            trigger_threshold: Порог триггера
            steering_strength: Сила стиринга
            max_new_tokens: Максимальное количество токенов
            verbose: Подробный вывод
            temperature: Температура генерации
            top_p: Top-p сэмплирование
            top_k: Top-k сэмплирование
            repetition_penalty: Штраф за повторения

        Returns:
            Сгенерированный текст
        """
        fact = self.fact_data[fact_id]
        steering_vec = fact['steering']
        trigger_vec = fact['trigger']

        inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
        input_ids = inputs['input_ids']

        trigger_detected = False
        trigger_similarities = []
        hooks = []
        generated_tokens = []

        def make_attn_hook(layer_idx):
            def hook_fn(module, input, output):
                nonlocal trigger_detected, trigger_similarities
                if not trigger_detected and layer_idx in trigger_vec:
                    current_act = output[0][:, -1, :].detach().cpu().numpy()[0]
                    similarity = self.cosine_similarity(current_act, trigger_vec[layer_idx])
                    trigger_similarities.append((layer_idx, similarity))

                    if similarity > trigger_threshold:
                        trigger_detected = True
                return output
            return hook_fn

        def make_mlp_hook(layer_idx):
            def hook_fn(module, input, output):
                if trigger_detected and layer_idx in steering_vec:
                    current_strength = steering_strength

                    if len(generated_tokens) > 0:
                        last_token = generated_tokens[-1]
                        if len(generated_tokens) >= 3 and all(t == last_token for t in generated_tokens[-3:]):
                            current_strength *= 0.5

                    steering_val = steering_vec[layer_idx]
                    steering_tensor = torch.from_numpy(current_strength * steering_val)
                    steering_tensor = steering_tensor.to(output.device).to(output.dtype)
                    output[:, -1, :] = output[:, -1, :] + steering_tensor

                return output
            return hook_fn

        # Регистрация хуков
        for layer_idx in trigger_vec:
            if layer_idx < len(self.model.model.layers):
                hook = make_attn_hook(layer_idx)
                handle = self.model.model.layers[layer_idx].self_attn.register_forward_hook(hook)
                hooks.append(handle)

        for layer_idx in steering_vec:
            if layer_idx < len(self.model.model.layers):
                hook = make_mlp_hook(layer_idx)
                handle = self.model.model.layers[layer_idx].mlp.register_forward_hook(hook)
                hooks.append(handle)

        generated_ids = []
        try:
            for step in range(max_new_tokens):
                with torch.no_grad():
                    outputs = self.model(input_ids=input_ids)

                next_token_logits = outputs.logits[:, -1, :]

                if repetition_penalty != 1.0:
                    for token_id in set(generated_ids):
                        next_token_logits[0, token_id] /= repetition_penalty

                if temperature > 0:
                    next_token_logits = next_token_logits / temperature

                    if top_k > 0:
                        indices_to_remove = next_token_logits < torch.topk(next_token_logits, top_k)[0][..., -1, None]
                        next_token_logits[indices_to_remove] = -float('Inf')

                    if top_p < 1.0:
                        sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)
                        cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)
                        sorted_indices_to_remove = cumulative_probs > top_p
                        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()
                        sorted_indices_to_remove[..., 0] = 0
                        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)
                        next_token_logits[indices_to_remove] = -float('Inf')

                    probs = torch.softmax(next_token_logits, dim=-1)
                    next_token = torch.multinomial(probs, num_samples=1)
                else:
                    next_token = next_token_logits.argmax(-1, keepdim=True)

                input_ids = torch.cat([input_ids, next_token], dim=-1)
                token_id = next_token.item()
                generated_ids.append(token_id)
                generated_tokens.append(token_id)

        finally:
            for hook in hooks:
                hook.remove()

        return self.tokenizer.decode(generated_ids, skip_special_tokens=True)
